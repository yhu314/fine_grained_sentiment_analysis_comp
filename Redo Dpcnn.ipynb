{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Yi\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.utils import to_categorical\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = ['../datasets/train_data_jieba.txt', '../datasets/valid_data_jieba.txt', '../datasets/test_data_jieba.txt']\n",
    "X_train = []\n",
    "X_valid = []\n",
    "X_test = []\n",
    "\n",
    "with open('../datasets/train_data_jieba.txt', 'r', encoding='utf8') as handle:\n",
    "    for line in handle.readlines():\n",
    "        X_train.append(line.rstrip('\\n'))\n",
    "        \n",
    "        \n",
    "with open('../datasets/valid_data_jieba.txt', 'r', encoding='utf8') as handle:\n",
    "    for line in handle.readlines():\n",
    "        X_valid.append(line.rstrip('\\n'))\n",
    "        \n",
    "        \n",
    "with open('../datasets/test_data_jieba.txt', 'r', encoding='utf8') as handle:\n",
    "    for line in handle.readlines():\n",
    "        X_test.append(line.rstrip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = ['location_traffic_convenience',\n",
    "       'location_distance_from_business_district', 'location_easy_to_find',\n",
    "       'service_wait_time', 'service_waiters_attitude',\n",
    "       'service_parking_convenience', 'service_serving_speed', 'price_level',\n",
    "       'price_cost_effective', 'price_discount', 'environment_decoration',\n",
    "       'environment_noise', 'environment_space', 'environment_cleaness',\n",
    "       'dish_portion', 'dish_taste', 'dish_look', 'dish_recommendation',\n",
    "       'others_overall_experience', 'others_willing_to_consume_again']\n",
    "train_data = pd.read_csv('../datasets/sentiment_analysis_trainingset.csv')\n",
    "valid_data = pd.read_csv('../datasets/sentiment_analysis_validationset.csv')\n",
    "\n",
    "y_train = []\n",
    "y_valid = []\n",
    "for N in name:\n",
    "    Y_train = train_data[[N]]\n",
    "    Y_train = np.array(Y_train)+2\n",
    "    Y_train = to_categorical(Y_train, num_classes=4)\n",
    "    y_train.append(Y_train)\n",
    "    \n",
    "    Y_valid = valid_data[[N]]\n",
    "    Y_valid = np.array(Y_valid)+2\n",
    "    Y_valid = to_categorical(Y_valid, num_classes=4)\n",
    "    y_valid.append(Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_path = '../datasets/tencent_embedding.npy'\n",
    "# 词典大小，embedding矩阵大小\n",
    "tok2idx_path = '../datasets/vocab.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "embedding_matrix = np.load(embedding_path)\n",
    "with open(tok2idx_path, 'rb') as file:\n",
    "    tok2idx = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(sentence, tok2idx):\n",
    "    return [tok2idx[word] for word in sentence.split(' ')]\n",
    "\n",
    "maxlen = 1024\n",
    "train = [tokenize(x, tok2idx) for x in X_train]\n",
    "valid = [tokenize(x, tok2idx) for x in X_valid]\n",
    "test = [tokenize(x, tok2idx) for x in X_test]\n",
    "x_train = pad_sequences(train, maxlen=maxlen, padding='pre')\n",
    "x_valid = pad_sequences(valid, maxlen=maxlen, padding='pre')\n",
    "x_test = pad_sequences(test, maxlen=maxlen, padding='pre')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Builde Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Input, GlobalAveragePooling1D, Dense\n",
    "from keras import backend as K\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.9\n",
    "config.gpu_options.allow_growth=True\n",
    "set_session(tf.Session(config=config))\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(input_dim=embedding_matrix.shape[0],\n",
    "                            output_dim=embedding_matrix.shape[1],\n",
    "                            weights=[embedding_matrix],\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_input = Input((maxlen,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence_embed = embedding_layer(sentence_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv1 = Conv1D(10, 3, activation='relu')(sentence_embed)\n",
    "conv\n",
    "conv2 = Conv1D(10, 3, activation='relu')(conv1)\n",
    "conv3 = Conv1D(10, 3, activation='relu')(conv2)\n",
    "flat = GlobalAveragePooling1D()(conv3)\n",
    "\n",
    "out_list = []\n",
    "for target in name:\n",
    "    out = Dense(4, activation='softmax', name=target)(flat)\n",
    "    out_list.append(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Model(sentence_input, out_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile('adam', 'categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "105000/105000 [==============================] - 103s 985us/step - loss: 16.0326 - location_traffic_convenience_loss: 0.5892 - location_distance_from_business_district_loss: 0.5481 - location_easy_to_find_loss: 0.6991 - service_wait_time_loss: 0.4994 - service_waiters_attitude_loss: 1.1267 - service_parking_convenience_loss: 0.3103 - service_serving_speed_loss: 0.5924 - price_level_loss: 1.2207 - price_cost_effective_loss: 0.7309 - price_discount_loss: 0.9894 - environment_decoration_loss: 0.9187 - environment_noise_loss: 0.8045 - environment_space_loss: 0.9617 - environment_cleaness_loss: 0.8869 - dish_portion_loss: 1.1189 - dish_taste_loss: 0.9363 - dish_look_loss: 0.7944 - dish_recommendation_loss: 0.6221 - others_overall_experience_loss: 0.8110 - others_willing_to_consume_again_loss: 0.8717\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28132de0fd0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
